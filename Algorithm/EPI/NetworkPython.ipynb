{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- initialisation: to set the number of input, hidden and output nodes\n",
    "\n",
    "- train: refine the weights after being given a trainingset example to learn from \n",
    "\n",
    "- query: give an answer from the output nodes after being given an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork():\n",
    "    # initialisa the neural network\n",
    "    def __init__(self, input_nodes_num, hidden_nodes_num, output_nodes_num, learning_rate):\n",
    "        # set number of nodes in each input, hidden, ouput layer\n",
    "        self.inodes = input_nodes_num\n",
    "        self.hnodes = hidden_nodes_num\n",
    "        self.onodes = output_nodes_num\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        # Weights: The Heart of the Network\n",
    "        self.w_ih = (np.random.rand(self.hnodes, self.inodes) - 0.5)\n",
    "        self.w_ho = (np.random.rand(self.onodes, self.hnodes) - 0.5)\n",
    "        \n",
    "        # 1/√(number of incoming links).\n",
    "        self.w_ih = np.random.normal(0.0, pow(self.hnodes, -0.5),\n",
    "                                    (self.hnodes, self.inodes))\n",
    "        self.w_ho = np.random.normal(0.0, pow(self.onodes, -0.5),\n",
    "                                    (self.onodes, self.hnodes))\n",
    "        # activate funcation is the sigmoid funcation\n",
    "        self.activate_funcation = lambda x:scipy.special.expit(x)\n",
    "        \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs = np.dot(self.w_ih, inputs)\n",
    "        hidden_outputs = self.activate_funcation(hidden_inputs)\n",
    "        \n",
    "        final_inputs = np.dot(self.w_ho, hidden_outputs)\n",
    "        final_outputs = self.activate_funcation(final_inputs)\n",
    "        \n",
    "        ###### Back propagated errors ########\n",
    "        output_error = targets - final_outputs\n",
    "        # Calculate the back propagated errors for the hidden layer nodes\n",
    "        # error_hidden = weights^T_hidden_output * error_output\n",
    "        hidden_error = np.dot(self.w_ho.T, output_error)\n",
    "\n",
    "        ###### Update the weights ########\n",
    "        # update the weights for the links between the hidden and output\n",
    "        self.w_ho += self.lr * np.dot((output_error * final_outputs*(1.0-final_outputs)),np.transpose(hidden_outputs))\n",
    "        # update the weights for the links between the hidden and input\n",
    "        self.w_ih += self.lr * np.dot((hidden_error * hidden_outputs*(1.0-hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "    def query(self, inputs_list):\n",
    "        # X_hidden = W_input_hidden ∙ I\n",
    "        hidden_inputs = np.dot(self.w_ih, inputs_list)\n",
    "        # O_hidden = sigmoid(X_hidden)\n",
    "        hidden_outputs = self.activate_funcation(hidden_inputs)\n",
    "        \n",
    "        final_inputs = np.dot(self.w_ho, hidden_inputs)\n",
    "        final_outputs = self.activate_funcation(final_inputs)\n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28*28\n",
    "input_nodes_num = 784\n",
    "hidden_nodes_num = 100\n",
    "# 10个目标数字\n",
    "output_nodes_num = 10\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "n = neuralNetwork(input_nodes_num, hidden_nodes_num, output_nodes_num, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n.query([1,0.5,-1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 根据指定的训练样本计算输出\n",
    "2. 将计算得到的输出与所需输出对比，使用差值来指导网络权重的更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST\n",
    "    - 28x28=784\n",
    "    - 标记和像素值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset: https://pjreddie.com/projects/mnist-in-csv/\n",
    "training_data_file = open(\"/Users/yogayu/Documents/code/makeyourownneuralnetwork/mnist_dataset/mnist_train.csv\",'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1513dbe470>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1513ba7240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_values = data_list[5].split(',')\n",
    "# asfarray: 将文本字符串转化为实数，并创建这些数字的数组\n",
    "# reshape: 转化为28*28 的方形矩阵\n",
    "image_array = np.asfarray(all_values[1:]).reshape((28,28))\n",
    "plt.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    # 遍历每一个训练集数据\n",
    "    for record in training_data_list:\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values, (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(output_nodes_num) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset: https://pjreddie.com/projects/mnist-in-csv/\n",
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"/Users/yogayu/Documents/code/makeyourownneuralnetwork/mnist_dataset/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# 遍历每一个测试集数据\n",
    "for record in test_data_list:\n",
    "    all_values = record.split(',')\n",
    "    correct_label = int(all_values[0])\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = np.argmax(outputs)\n",
    "    \n",
    "    if label == correct_label:\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.0998\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs=1\n",
    "\n",
    "0.1->0.1169\n",
    "0.1->0.1318\n",
    "\n",
    "epochs=5\n",
    "\n",
    "0.1->0.098\n",
    "0.3->0.098\n",
    "0.6->0.098\n",
    "\n",
    "epochs = 5\n",
    "hnodes=200\n",
    "lr=0.1\n",
    "performance =  0.098\n",
    "\n",
    "epochs = 1\n",
    "0.1075\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "hnodes = 100\n",
    "lr = 0.1\n",
    "0.0998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备 MNIST 训练数据\n",
    "- 将输入色彩值从0-255的范围，缩放至0.01-1.0的范围。不取0值，因为0会导致权值更新失败。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.04105882 0.46423529 0.99611765 0.86411765 0.35552941\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.06047059 0.37882353 0.83305882\n",
      " 0.99223529 0.99223529 0.99223529 0.61952941 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.07211765\n",
      " 0.37882353 0.82141176 0.99223529 0.99223529 0.99223529 0.96117647\n",
      " 0.49529412 0.07988235 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.16529412 0.38270588 0.80976471 0.99223529 0.99611765\n",
      " 0.99223529 0.99223529 0.77870588 0.25847059 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.18082353 0.71658824 0.94176471\n",
      " 0.99223529 0.99223529 0.99223529 0.99611765 0.99223529 0.77870588\n",
      " 0.10317647 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.06823529 0.24294118 0.24294118 0.66223529 0.99223529\n",
      " 0.99223529 0.99611765 0.78647059 0.09929412 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.28176471 0.96894118 0.99223529 0.99223529 0.96117647\n",
      " 0.09152941 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.30117647 0.81364706\n",
      " 0.99223529 0.99223529 0.81364706 0.36717647 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.31670588 0.86023529 0.99223529 0.99223529 0.99223529\n",
      " 0.54576471 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.41764706 0.98058824\n",
      " 0.99223529 0.99223529 0.99223529 0.142      0.01388235 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.37882353 0.99611765 0.99611765 0.99611765 0.99611765\n",
      " 0.37494118 0.01       0.01       0.01       0.01       0.01\n",
      " 0.02164706 0.06047059 0.06047059 0.06047059 0.04105882 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.42541176\n",
      " 0.99223529 0.99223529 0.99223529 0.802      0.06823529 0.01\n",
      " 0.01       0.01       0.01       0.09152941 0.65447059 0.99223529\n",
      " 0.99223529 0.99223529 0.83305882 0.10705882 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.13811765 0.85247059 0.99223529 0.99223529\n",
      " 0.52247059 0.25847059 0.01       0.01       0.07988235 0.17694118\n",
      " 0.61952941 0.67388235 0.99223529 0.99223529 0.99223529 0.99223529\n",
      " 0.99223529 0.63117647 0.01776471 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.02164706\n",
      " 0.65447059 0.99223529 0.99223529 0.94952941 0.20023529 0.076\n",
      " 0.20023529 0.62341176 0.82529412 0.99611765 0.99223529 0.99223529\n",
      " 0.99223529 0.99223529 0.99223529 0.99223529 0.99223529 0.99223529\n",
      " 0.05270588 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.04882353 0.89129412 0.99223529\n",
      " 0.99223529 0.81364706 0.06823529 0.67776471 0.99223529 0.99223529\n",
      " 0.99223529 0.99611765 0.96894118 0.79035294 0.99223529 0.82529412\n",
      " 0.82529412 0.99223529 0.99223529 0.68941176 0.02552941 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.04882353 0.89517647 0.99223529 0.99223529 0.87964706\n",
      " 0.34776471 0.94952941 0.99223529 0.99223529 0.72435294 0.24294118\n",
      " 0.21964706 0.04494118 0.24294118 0.14588235 0.71658824 0.99223529\n",
      " 0.99223529 0.21188235 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.06047059\n",
      " 0.99223529 0.99223529 0.99223529 0.99223529 0.90682353 0.99223529\n",
      " 0.99223529 0.99223529 0.37105882 0.34388235 0.34388235 0.34388235\n",
      " 0.43317647 0.85247059 0.99223529 0.99223529 0.53023529 0.02941176\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01776471 0.45647059 0.99223529\n",
      " 0.99223529 0.99223529 0.99223529 0.99223529 0.99223529 0.99223529\n",
      " 0.99223529 0.99611765 0.99223529 0.99223529 0.99223529 0.99223529\n",
      " 0.99223529 0.53023529 0.02941176 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.02164706 0.65447059 0.99223529 0.99223529\n",
      " 0.99223529 0.99223529 0.99223529 0.99223529 0.99223529 0.99611765\n",
      " 0.99223529 0.99223529 0.99223529 0.68941176 0.21188235 0.02941176\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.03717647 0.14588235 0.52247059 0.88352941 0.99223529\n",
      " 0.99223529 0.99223529 0.76705882 0.52247059 0.52247059 0.52247059\n",
      " 0.43705882 0.02552941 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01      ]\n"
     ]
    }
   ],
   "source": [
    "# scale input to range 0.01 to 1.00\n",
    "# 0-255 转为 0-1，再乘0.99转为 0-0.99，在加0.01转为 0.01到1.0\n",
    "scaled_input = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output nodes is 10\n",
    "# 设置输出为10个节点\n",
    "onodes = 10\n",
    "# 创建默认值为0.01的节点\n",
    "targets = np.zeros(onodes) + 0.01\n",
    "# 将目标标签转为整数\n",
    "# 将目标列表的正确元素设置为0.99\n",
    "targets[int(all_values[0])] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
